{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5ojYZ2MtEw8PwbOx3TDhz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a2c6201/machine-learning-book/blob/main/ch16/ch16_%E8%AA%B2%E9%A1%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers\n",
        "!wget https://storage.googleapis.com/what-if-tool-resources/lit-models/sst2_tiny.tar.gz\n",
        "!tar -xvf sst2_tiny.tar.gz\n",
        "!pip install lit_nlp tfds-nightly\n",
        "!pip install lime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bs5TlVm4O_NE",
        "outputId": "ca604836-3000-4cbf-9292-6c36c9f4d838"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/7.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/7.2 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m6.9/7.2 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n",
            "--2023-07-05 06:31:57--  https://storage.googleapis.com/what-if-tool-resources/lit-models/sst2_tiny.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.117.128, 142.250.107.128, 74.125.20.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.117.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16362834 (16M) [application/octet-stream]\n",
            "Saving to: ‘sst2_tiny.tar.gz’\n",
            "\n",
            "sst2_tiny.tar.gz    100%[===================>]  15.60M  54.1MB/s    in 0.3s    \n",
            "\n",
            "2023-07-05 06:31:57 (54.1 MB/s) - ‘sst2_tiny.tar.gz’ saved [16362834/16362834]\n",
            "\n",
            "./\n",
            "./tokenizer_config.json\n",
            "./tf_model.h5\n",
            "./config.json\n",
            "./train.history.json\n",
            "./vocab.txt\n",
            "./special_tokens_map.json\n",
            "Collecting lit_nlp\n",
            "  Downloading lit_nlp-0.5.0-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tfds-nightly\n",
            "  Downloading tfds_nightly-4.9.2.dev202307050045-py3-none-any.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from lit_nlp) (1.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from lit_nlp) (23.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lit_nlp) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lit_nlp) (1.10.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from lit_nlp) (1.5.3)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.10/dist-packages (from lit_nlp) (1.5.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lit_nlp) (1.2.2)\n",
            "Collecting sacrebleu (from lit_nlp)\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting umap-learn (from lit_nlp)\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Werkzeug in /usr/local/lib/python3.10/dist-packages (from lit_nlp) (2.3.6)\n",
            "Collecting ml-collections (from lit_nlp)\n",
            "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tfds-nightly) (0.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tfds-nightly) (8.1.3)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tfds-nightly) (0.1.8)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tfds-nightly) (1.3.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tfds-nightly) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tfds-nightly) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tfds-nightly) (5.9.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tfds-nightly) (2.27.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tfds-nightly) (1.13.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tfds-nightly) (2.3.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tfds-nightly) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tfds-nightly) (4.65.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tfds-nightly) (1.14.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tfds-nightly) (5.12.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tfds-nightly) (4.6.3)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tfds-nightly) (3.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tfds-nightly) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tfds-nightly) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tfds-nightly) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tfds-nightly) (3.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from ml-collections->lit_nlp) (6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from ml-collections->lit_nlp) (1.16.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from ml-collections->lit_nlp) (0.6.0.post1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lit_nlp) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lit_nlp) (2022.7.1)\n",
            "Collecting portalocker (from sacrebleu->lit_nlp)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->lit_nlp) (2022.10.31)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->lit_nlp) (0.8.10)\n",
            "Collecting colorama (from sacrebleu->lit_nlp)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->lit_nlp) (4.9.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lit_nlp) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lit_nlp) (3.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tfds-nightly) (1.59.1)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.10/dist-packages (from umap-learn->lit_nlp) (0.56.4)\n",
            "Collecting pynndescent>=0.5 (from umap-learn->lit_nlp)\n",
            "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from Werkzeug->lit_nlp) (2.1.3)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->umap-learn->lit_nlp) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->umap-learn->lit_nlp) (67.7.2)\n",
            "Building wheels for collected packages: ml-collections, umap-learn, pynndescent\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94506 sha256=d20ca67d33366f6f59eb41f7b0264260b83982dc0bc6f1d2a3e6072bb46f71a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/89/c9/a9b87790789e94aadcfc393c283e3ecd5ab916aed0a31be8fe\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82816 sha256=9fd3e55222ecc657c539cfc8b52d3212ba5d85b0d3d77bf83643a61cdf3cd377\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/e8/c6/a37ea663620bd5200ea1ba0907ab3c217042c1d035ef606acc\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55622 sha256=8cde18bf1e9d8b31ce433bc714a98b7bdcaaffdc3500c4d9650e7e57d3453489\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/38/5d/f60a40a66a9512b7e5e83517ebc2d1b42d857be97d135f1096\n",
            "Successfully built ml-collections umap-learn pynndescent\n",
            "Installing collected packages: portalocker, ml-collections, colorama, sacrebleu, pynndescent, umap-learn, tfds-nightly, lit_nlp\n",
            "Successfully installed colorama-0.4.6 lit_nlp-0.5.0 ml-collections-0.1.1 portalocker-2.7.0 pynndescent-0.5.10 sacrebleu-2.3.1 tfds-nightly-4.9.2.dev202307050045 umap-learn-0.5.3\n",
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.10.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.65.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.19.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (8.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (23.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283839 sha256=bfe8067fd4333d5160ca67d5b166dc70c1bf5ba6206355b271445608e5ab23dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/a2/af/9ac0a1a85a27f314a06b39e1f492bee1547d52549a4606ed89\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import  AutoModel, AutoTokenizer, get_cosine_schedule_with_warmup, AdamW, BertConfig\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython.display import display, HTML\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "HAmrKzJSM2nU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# データの準備"
      ],
      "metadata": {
        "id": "OjSCa977xE7J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IMDBデータセットを取得\n",
        "すでにトークナイズ（文章をトークンに分解し、BERTに入力できる形にすること）されている？"
      ],
      "metadata": {
        "id": "O3gdemyjM6jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb\n",
        "\n",
        "SEED = 0\n",
        "\n",
        "# データの読み込み\n",
        "# label_dic : 0がnegativeで、1がpositive\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000, seed=SEED)  # データの読み込み"
      ],
      "metadata": {
        "id": "6udXYi7DNE9-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "データの確認"
      ],
      "metadata": {
        "id": "lobN0h7E8V3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 単語を整数にマッピングする辞書\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# インデックスの最初の方は予約済み\n",
        "word_index = {k:(v+3) for k,v in word_index.items()}\n",
        "word_index[\"\"] = 0\n",
        "word_index[\"\"] = 1\n",
        "word_index[\"\"] = 2  # unknown\n",
        "word_index[\"\"] = 3\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4zK3qZOTFYq",
        "outputId": "693a1d29-94d3-44e2-8ccf-ee8c8acfd7ed"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1641221/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('x_train.shape:', x_train.shape)\n",
        "print('x_train[0]:', x_train[0])\n",
        "print(decode_review(x_train[0]))\n",
        "print('-----------------------')\n",
        "print('y_train.shape:', y_train.shape)\n",
        "print('-----------------------')\n",
        "print('x_test.shape:', x_test.shape)\n",
        "print('y_test:', y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqeGAuxzQL1f",
        "outputId": "c3e79909-9715-4499-a19f-a194de4e8b6c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape: (25000,)\n",
            "x_train[0]: [1, 4078, 2, 9, 448, 725, 4, 2, 241, 2, 241, 38, 111, 2, 500, 40, 91, 374, 500, 679, 102, 13, 62, 135, 4, 2159, 92, 7241, 83, 6, 275, 3449, 66, 73, 5, 15, 271, 18, 14, 31, 99, 2149, 10, 10, 225, 6, 184, 196, 8127, 63, 2568, 5, 732, 4, 863, 18, 4, 65, 5, 4, 1397, 1111, 23, 63, 6, 564, 4892, 2, 5, 27, 476, 577, 2, 2, 2, 5, 492, 2, 2, 2, 216, 8, 847, 83, 4, 9370, 92, 168, 32, 99, 2575, 5, 515, 195, 481, 2017, 9, 348, 44, 4, 2, 23, 4, 1111, 8, 789, 2, 280, 4, 2, 517, 2, 10, 10, 1958, 5, 1364, 183, 380, 8, 140, 2, 5, 263, 6308, 140, 23, 6, 1973, 3318, 187, 4, 3450, 8, 1974, 618, 51, 9, 1448, 23, 14, 2, 1111, 19, 94, 680, 5818, 21, 11, 882, 25, 80, 24, 1414, 19, 803, 170, 23, 17, 2, 5, 2447, 2953, 79, 1376, 11, 8, 2, 4, 114, 60, 53, 51, 16, 66, 3742, 12, 83, 4, 5513, 7, 78, 212, 26, 94, 2, 1815, 2611, 46, 7, 4, 5797, 388, 63, 43, 2266, 5342, 2, 33, 94, 2099, 3002, 366, 45, 1852, 76, 303, 45, 31, 155, 269, 8, 216, 56, 5, 984, 142, 1393, 21, 160, 155, 399, 12, 4521, 5, 19, 2, 2380, 10, 10, 466, 12, 2, 11, 467, 1552, 234, 13, 104, 45, 6, 189, 20, 5682, 8, 28, 15, 17, 6, 9848, 2, 12, 408, 15, 220, 107, 534, 235, 19, 94, 550, 2, 8, 376, 51, 12, 494, 8, 183, 895, 8, 1261, 56, 1841, 4, 236, 891, 234, 21, 45, 6, 356, 420, 7, 99, 117, 99, 522, 10, 10, 51, 3220, 4, 20, 9, 89, 12, 1443, 2, 5, 94, 3411, 33, 4, 130, 174, 14, 9, 6, 1141, 2701, 343, 8, 353, 5, 9330, 6, 1573, 606, 189, 20, 83, 142, 6, 117, 227, 1727, 11, 4, 440, 7, 2, 35, 311, 12, 679, 46, 247, 2, 21, 889, 6, 78, 2, 17, 490, 235, 4563, 643, 50, 26, 107, 771, 6, 1009, 80, 97, 25, 235, 12, 345, 2, 4, 20, 8, 6, 906, 651, 42, 1568, 25, 19, 15, 5667, 547, 472, 4078, 2, 2, 53, 8, 4, 1569, 10, 10, 4, 1907, 1698, 80, 30, 94, 627, 19, 94, 361, 7, 641, 3788, 5, 6048, 21, 13, 80, 30, 15, 3759, 45, 131, 24, 290, 4, 58, 38, 128, 8, 798, 14]\n",
            "? forbidden ? is based upon the ? 2 ? 2 so many ? game like most video game turned movies i would say the majority don't translate into a different medium really well and that goes for this one too painfully br br there's a pretty long prologue which explains and sets the premise for the story and the mysterious island on which a writer leo ? and his children daughter ? ? ? and son ? ? ? come to move into the villagers don't look all too friendly and soon enough sound advice is given about the ? on the island to stay ? once the ? starts ? br br naturally and slowly things start to go ? and our siblings go on a mission beating around the bush to discover exactly what is happening on this ? island with its strange inhabitants but in truth you will not bother with what's going on as ? and fairy tales get thrown in to ? the plot even more what was really pushing it into the realm of bad comedy are its ? ill placed out of the norm moments which just drew pitiful ? at its sheer stupidity until it's explained much later it's one thing trying to come up and present something smart but another thing doing it convincingly and with ? covered br br despite it ? in under 90 minutes i think it's a horror movie phenomenon to have that as a runtime ? it gives that almost two hour feel with its slow ? to tell what it wants to things begin to pick up toward the last 20 minutes but it's a classic case of too little too late br br what saves the movie is how it changes ? and its revelation at the end again this is a common device used to try and elevate a seemingly simple horror movie into something a little bit extra in the hope of ? an audience it turned out rather ? but leaves a bad ? as you'll feel cheated somewhat there are two ways a twist will make you feel it either ? the movie to a memorable level or provides you with that hokey feeling unfortunately forbidden ? ? more to the latter br br the saving grace will be its cinematography with its use of light shadows and mirrors but i will be that explicit it's still not worth the time so better to avoid this\n",
            "-----------------------\n",
            "y_train.shape: (25000,)\n",
            "-----------------------\n",
            "x_test.shape: (25000,)\n",
            "y_test: [0 1 0 ... 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習"
      ],
      "metadata": {
        "id": "17ggzU-R808n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "label_dic = {'ham': 0, 'spam': 1}  # spamを真値とする\n",
        "label_dic_inv = {v: k for k, v in label_dic.items()}\n",
        "label_ids = [label_dic[i] for i in labels]\n",
        "\n",
        "# 7:3に学習データとテストデータを分割する(30%がテストデータ)\n",
        "train_sentence, test_sentence, y_train, y_test = train_test_split(sentences, label_ids, test_size=0.3, random_state=SEED, stratify=label_ids)"
      ],
      "metadata": {
        "id": "-0zrBNxuQC5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## traintestspilit使う\n",
        "## ham, spamを言い方悪い方に変える\n",
        "## 文字数が多いのでエポックかかりそう"
      ],
      "metadata": {
        "id": "-n3q0W6mUiGR"
      }
    }
  ]
}